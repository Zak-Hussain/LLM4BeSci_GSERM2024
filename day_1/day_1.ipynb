{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Using Notebook Environments \n",
    "1. To run a cell, press `shift + enter`. The notebook will execute the code in the cell and move to the next cell. If the cell contains a markdown cell (text only), it will render the markdown and move to the next cell.\n",
    "2. Since cells can be executed in any order and variables can be over-written, you may at some point feel that you have lost track of the state of your notebook. If this is the case, you can always restart the kernel by clicking Runtime in the menu bar (if you're using Colab) and selecting `Restart runtime`. This will clear all variables and outputs.\n",
    "3. The final variable in a cell will be printed on the screen. If you want to print multiple variables, use the `print()` function as usual.\n",
    "\n",
    "Notebook environments support code cells and markdown cells. For the purposes of this workshop, markdown cells are used to provide high-level explanations of the code. More specific details are provided in the code cells themselves in the form of comments (lines beginning with `#`)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "979416b3c30fb86b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup (run before presentation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e95bbbdb5e332796"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:  # If in Google Colab environment\n",
    "    # Installing requisite packages\n",
    "    !pip install transformers sentence-transformers &> /dev/null\n",
    "\n",
    "    # Mount google drive to enable access to data files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Change working directory to health\n",
    "    %cd /content/drive/MyDrive/LLM4BeSci_GSERM2024/day_1"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We begin by loading the requisite packages. For those coming from R, packages in Python are sometimes given shorter names for use in the code via the `import <name> as <nickname>` syntax (e.g. `import pandas as pd`). These are usually standardized nicknames. We here make use three packages:\n",
    "\n",
    "1. `pandas`: A very popular package for reading and manipulating data in python.\n",
    "2. `sentence_transformers`: A package for extracting features from text data using transformer-based models.\n",
    "3. `transformers`: A HF package for loading and manipulating transformer-based models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "290c24c2ed829f80"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T12:17:10.069389Z",
     "start_time": "2024-05-25T12:17:04.914207Z"
    }
   },
   "id": "267fad62d6f82855",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/890M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0a51540e08d43c889b2af0ad40466b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80d978ecc0f242afad30aaa065ae7fbf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24c4c4d9175c452aa2e3ee56963178ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f413d74e8fa942348aca05762a914d3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d743ba992ea3429093107b678478421e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<transformers.pipelines.text_generation.TextGenerationPipeline at 0x7f85a35ac790>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installs relevant models by running pipelines (ignore details here) \n",
    "SentenceTransformer('all-MiniLM-L6-v2')\n",
    "pipeline('zero-shot-classification', model='valhalla/distilbart-mnli-12-1')\n",
    "pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "pipeline('text-generation', model='gpt2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T12:43:34.332951Z",
     "start_time": "2024-05-25T12:31:43.386077Z"
    }
   },
   "id": "1a8423f626867855",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "[RUN TILL HERE BEFORE PRESENTATION]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e53bb65e802730bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Feature Extraction\n",
    "\n",
    "We will begin by extracting features (numerical representations) from the text data using the `sentence-transformers` package. We will use the following three sentences:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6bf097acf12ea11"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                   0         1         2         3     \nI feel great this morning    -0.026462 -0.044373  0.072443  0.034526  \\\nI am feeling very good today -0.043895 -0.020341  0.066563 -0.006310   \nI am feeling terrible         0.017495 -0.057904  0.033315  0.001710   \n\n                                   4         5         6         7     \nI feel great this morning     0.089534 -0.050451  0.018811  0.071296  \\\nI am feeling very good today  0.025980 -0.040420  0.079304 -0.009700   \nI am feeling terrible         0.051957 -0.048159  0.007659  0.119096   \n\n                                   8         9    ...       374       375   \nI feel great this morning    -0.020522 -0.043637  ... -0.005689 -0.000328  \\\nI am feeling very good today -0.042920 -0.025988  ... -0.045309  0.049151   \nI am feeling terrible         0.029929 -0.068960  ...  0.038813  0.003015   \n\n                                   376       377       378       379   \nI feel great this morning    -0.049055  0.016308 -0.027642  0.017276  \\\nI am feeling very good today -0.049057  0.017821 -0.018061 -0.010441   \nI am feeling terrible        -0.074585 -0.018391 -0.026449  0.005867   \n\n                                   380       381       382       383  \nI feel great this morning     0.065253  0.017496 -0.022810 -0.036687  \nI am feeling very good today  0.043070  0.018440 -0.008274 -0.006016  \nI am feeling terrible         0.051495 -0.009829  0.030009 -0.064299  \n\n[3 rows x 384 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>374</th>\n      <th>375</th>\n      <th>376</th>\n      <th>377</th>\n      <th>378</th>\n      <th>379</th>\n      <th>380</th>\n      <th>381</th>\n      <th>382</th>\n      <th>383</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>I feel great this morning</th>\n      <td>-0.026462</td>\n      <td>-0.044373</td>\n      <td>0.072443</td>\n      <td>0.034526</td>\n      <td>0.089534</td>\n      <td>-0.050451</td>\n      <td>0.018811</td>\n      <td>0.071296</td>\n      <td>-0.020522</td>\n      <td>-0.043637</td>\n      <td>...</td>\n      <td>-0.005689</td>\n      <td>-0.000328</td>\n      <td>-0.049055</td>\n      <td>0.016308</td>\n      <td>-0.027642</td>\n      <td>0.017276</td>\n      <td>0.065253</td>\n      <td>0.017496</td>\n      <td>-0.022810</td>\n      <td>-0.036687</td>\n    </tr>\n    <tr>\n      <th>I am feeling very good today</th>\n      <td>-0.043895</td>\n      <td>-0.020341</td>\n      <td>0.066563</td>\n      <td>-0.006310</td>\n      <td>0.025980</td>\n      <td>-0.040420</td>\n      <td>0.079304</td>\n      <td>-0.009700</td>\n      <td>-0.042920</td>\n      <td>-0.025988</td>\n      <td>...</td>\n      <td>-0.045309</td>\n      <td>0.049151</td>\n      <td>-0.049057</td>\n      <td>0.017821</td>\n      <td>-0.018061</td>\n      <td>-0.010441</td>\n      <td>0.043070</td>\n      <td>0.018440</td>\n      <td>-0.008274</td>\n      <td>-0.006016</td>\n    </tr>\n    <tr>\n      <th>I am feeling terrible</th>\n      <td>0.017495</td>\n      <td>-0.057904</td>\n      <td>0.033315</td>\n      <td>0.001710</td>\n      <td>0.051957</td>\n      <td>-0.048159</td>\n      <td>0.007659</td>\n      <td>0.119096</td>\n      <td>0.029929</td>\n      <td>-0.068960</td>\n      <td>...</td>\n      <td>0.038813</td>\n      <td>0.003015</td>\n      <td>-0.074585</td>\n      <td>-0.018391</td>\n      <td>-0.026449</td>\n      <td>0.005867</td>\n      <td>0.051495</td>\n      <td>-0.009829</td>\n      <td>0.030009</td>\n      <td>-0.064299</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 384 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"I feel great this morning\",\n",
    "    \"I am feeling very good today\",\n",
    "    \"I am feeling terrible\"\n",
    "]\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Extract features\n",
    "features = model.encode(sentences)\n",
    "\n",
    "# Print the features as a pandas dataframe\n",
    "pd.DataFrame(features, index=sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T12:48:01.272161Z",
     "start_time": "2024-05-25T12:48:01.015684Z"
    }
   },
   "id": "98ca015d4695f403",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "TASK 1: Have a scroll through the features. Can you see that the first two sentences are more similar to each other than they are to the third sentence? Why do you think this is the case?\n",
    "\n",
    "TASK 2: Try copy-pasting one of the sentences and change a word or two with a synonym and add it to the list. For instance, you could change \"I feel *great* this morning\" to \"I feel *fantastic* this morning\". What do you notice about the features of this new sentence compared to the original?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b24a4ebcb90764d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zero-shot Classification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae5785bf66387433"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhussain/opt/anaconda3/envs/LLM4BeSci/lib/python3.8/site-packages/torch/utils/data/dataloader.py:693: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x7f85c40d3580> was reported to be 3 (when accessing len(dataloader)), but 4 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/zhussain/opt/anaconda3/envs/LLM4BeSci/lib/python3.8/site-packages/torch/utils/data/dataloader.py:693: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x7f85c40d3580> was reported to be 3 (when accessing len(dataloader)), but 5 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n",
      "/Users/zhussain/opt/anaconda3/envs/LLM4BeSci/lib/python3.8/site-packages/torch/utils/data/dataloader.py:693: UserWarning: Length of IterableDataset <transformers.pipelines.pt_utils.PipelineChunkIterator object at 0x7f85c40d3580> was reported to be 3 (when accessing len(dataloader)), but 6 samples have been fetched. \n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                  sequence   \nI feel great this morning        I feel great this morning  \\\nI am feeling very good today  I am feeling very good today   \nI am feeling terrible                I am feeling terrible   \n\n                                            labels   \nI feel great this morning     [positive, negative]  \\\nI am feeling very good today  [positive, negative]   \nI am feeling terrible         [negative, positive]   \n\n                                                                   scores  \nI feel great this morning      [0.9929565191268921, 0.007043477613478899]  \nI am feeling very good today   [0.9965097904205322, 0.003490227973088622]  \nI am feeling terrible         [0.9988492131233215, 0.0011507953749969602]  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>labels</th>\n      <th>scores</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>I feel great this morning</th>\n      <td>I feel great this morning</td>\n      <td>[positive, negative]</td>\n      <td>[0.9929565191268921, 0.007043477613478899]</td>\n    </tr>\n    <tr>\n      <th>I am feeling very good today</th>\n      <td>I am feeling very good today</td>\n      <td>[positive, negative]</td>\n      <td>[0.9965097904205322, 0.003490227973088622]</td>\n    </tr>\n    <tr>\n      <th>I am feeling terrible</th>\n      <td>I am feeling terrible</td>\n      <td>[negative, positive]</td>\n      <td>[0.9988492131233215, 0.0011507953749969602]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the zero-shot classification pipeline \n",
    "pipe = pipeline('zero-shot-classification', model='valhalla/distilbart-mnli-12-1')\n",
    "\n",
    "# Define the candidate labels\n",
    "candidate_labels = ['positive', 'negative']\n",
    "\n",
    "# Predict the labels of the sentences\n",
    "predictions = pipe(sentences, candidate_labels)\n",
    "\n",
    "# Print the predictions as a pandas dataframe\n",
    "pd.DataFrame(predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T12:48:06.774280Z",
     "start_time": "2024-05-25T12:48:02.248359Z"
    }
   },
   "id": "55dc7dc9726267e5",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sentiment Analysis "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4830e24a5d45430d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now load the `transformers` sentiment analysis pipeline to predict the sentiment of sentences. The pipeline is a high-level API that allows us to easily use pre-trained models for a variety of tasks. In this case, we will use a sentiment fine-tuned version of the DistilBERT model for sentiment analysis."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77a8852269ce709d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                 label     score\nI feel great this morning     POSITIVE  0.999873\nI am feeling very good today  POSITIVE  0.999872\nI am feeling terrible         NEGATIVE  0.999489",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>I feel great this morning</th>\n      <td>POSITIVE</td>\n      <td>0.999873</td>\n    </tr>\n    <tr>\n      <th>I am feeling very good today</th>\n      <td>POSITIVE</td>\n      <td>0.999872</td>\n    </tr>\n    <tr>\n      <th>I am feeling terrible</th>\n      <td>NEGATIVE</td>\n      <td>0.999489</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load sentiment analysis pipeline\n",
    "pipe = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "\n",
    "# Predict sentiment of the sentences\n",
    "sentiments = pipe(sentences)\n",
    "\n",
    "# Print the predicted sentiments as a pandas dataframe\n",
    "pd.DataFrame(sentiments, index=sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T12:17:31.692325Z",
     "start_time": "2024-05-25T12:17:30.447572Z"
    }
   },
   "id": "612fa14857dc0b74",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the pipeline loaded, we can now use it to predict the sentiment of the tweets. We will use the `tweet` column of the `twitter` dataframe as input to the pipeline."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e56f6900724dcc9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Text Generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efc8d5804ede6511"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now use the `transformers` text generation pipeline. We begin by loading the pipeline with the `gpt2` model. The pipeline will generate text based on a given prompt."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd5b4ccb4e39bc3f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pipe = pipeline('text-generation', model='gpt2')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T12:17:46.658344Z",
     "start_time": "2024-05-25T12:17:43.463806Z"
    }
   },
   "id": "574afec0d0b34779",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\n    Once upon a time in a land far far away, there was a young prince named John. He was known for his bravery and courage. \\n    One day, he decided to go on an adventure to explore the unknown lands.\\n    To enter the depths of the earth to learn more about the people he found, would be to face the unknown, or he might face the darkness that lies there. \\n    This prince named John grew'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "    Once upon a time in a land far far away, there was a young prince named John. He was known for his bravery and courage. \n",
    "    One day, he decided to go on an adventure to explore the unknown lands.\n",
    "\"\"\"\n",
    "\n",
    "# Generate text based on the prompt\n",
    "output = pipe(prompt, max_length=100)\n",
    "\n",
    "# Print the generated text\n",
    "output[0]['generated_text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-25T12:19:06.101237Z",
     "start_time": "2024-05-25T12:19:05.154616Z"
    }
   },
   "id": "cc96eb23af195ac2",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "TASK 1: Please enter any prompt you like in the variable `prompt` below that you wish the model to continue generating text from. Feel free to play around with the `max_length` parameter to see how it affects the generated text.\n",
    "\n",
    "TASK 2: Try replacing 'gpt2' above with 'gpt2-medium' or another text generation model on the [HF model hub](https://huggingface.co/models) to see how the generated text changes."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "308056004c14c19f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "81690eb2b6590715"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
