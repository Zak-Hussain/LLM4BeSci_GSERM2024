{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Environment Setup\n",
    "**Make sure to set your runtime to use a GPU by going to `Runtime` -> `Change runtime type` -> `Hardware accelerator` -> `T4 GPU`**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e75ca4df36940e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:  # If in Google Colab environment\n",
    "    # Mount google drive to enable access to data files\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    # Installing requisite packages\n",
    "    !pip install transformers accelerate pymupdf &> /dev/null\n",
    "    \n",
    "    # Change working directory to health\n",
    "    %cd /content/drive/MyDrive/LLM4BeSci_GSERM2024/day_5"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import fitz\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T13:28:17.997821Z",
     "start_time": "2024-06-01T13:28:15.772813Z"
    }
   },
   "id": "32d1a87f8f8f332b",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Data and Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a5bd305a250cc49"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Hussain et al. EPJ Data Science           ( 2024)  13:38 \\nhttps://doi.org/10.1140/epjds/s13688-024-00478-x\\nR ES EA RCH\\nOpen Access\\nNovel embeddings improve the prediction\\nof risk perception\\nZak Hussain1,2*\\n, Rui Mata1 and Dirk U. Wulﬀ1,2\\n*Correspondence:\\nz.hussain@unibas.ch\\n1Faculty of Psychology, University of\\nBasel, Missionsstrasse 60–62, Basel,\\n4055, Switzerland\\n2Center for Adaptive Rationality,\\nMax Planck Institute for Human\\nDevelopment, Lentzeallee 94, Berlin,\\n14195, Germany\\nAbstract\\nWe assess whether the classic psychometric paradigm of risk perception can be\\nimproved or supplanted by novel approaches relying on language embeddings. To\\nthis end, we introduce the Basel Risk Norms, a large data set covering 1004 distinct\\nsources of risk (e.g., vaccination, nuclear energy, artiﬁcial intelligence) and compare\\nthe psychometric paradigm against novel text and free-association embeddings in\\npredicting risk perception. We ﬁnd that an ensemble model combining text and free\\nassociation riv'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract text from PDF\n",
    "pdf = fitz.open('riskEmbeddings.pdf')\n",
    "text = \"\"\n",
    "for page in pdf:\n",
    "    text += page.get_text()\n",
    "\n",
    "text[:1000]  # Display the first 500 characters to verify content extraction"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-01T13:30:52.451408Z",
     "start_time": "2024-06-01T13:30:52.346200Z"
    }
   },
   "id": "60a303a9d552a2bc",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42) # For reproducibility\n",
    "\n",
    "# Load the model \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"microsoft/Phi-3-mini-128k-instruct\",\n",
    "    device_map=\"cuda\", # Use GPU\n",
    "    torch_dtype=torch.float16, # Use half-precision\n",
    "    trust_remote_code=True, \n",
    "    attn_implementation='eager' # For faster inference on T4 GPUs\n",
    ")\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cd46bddeb26563c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 1000,  # Maximum number of tokens to generate\n",
    "    \"return_full_text\": False, # Return only the generated text\n",
    "    \"do_sample\": False # Use greedy decoding\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "470ab4da8a3c25ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def query_paper(query):\n",
    "    prompt = [{\"role\": \"user\", \"content\": query + '\\n-------------------\\n' + text}]\n",
    "    output = pipe(prompt, **generation_args)\n",
    "    return output[0]['generated_text']\n",
    "\n",
    "q_1 = "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5d8be2fcc701d0e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "q_1 = \"What is the title of the following paper?\\n-------------------------\\n\"\n",
    "print(pipe([{\"role\": \"user\", \"content\": q_1 + text}])[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e64328e2f042e309"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "q_2 = \"Return to me the full abstract of the following paper:\\n-------------------------\\n\"\n",
    "print(pipe([{\"role\": \"user\", \"content\": q_2 + text}])[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cd47c8ca5e6faf4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "q_3 = \"Summarise the following paper:\\n-------------------------\\n\"\n",
    "print(pipe([{\"role\": \"user\", \"content\": q_3 + text}])[0]['generated_text'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf40b0d6612c4b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
